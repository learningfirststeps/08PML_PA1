q()
getwd()
dir()
getwd()
q()
install.packages("slidify")
install.packages("ggplot2")
install.packages("slidify")
clear
library(datasets)
data(iris)
?iris
iris
iris3
iris3$Virginica
iris3[Virginica]
iris3[[Virginica]]
iris$Sepal.Length
levels(iris[Species])
levels(iris$Species)
tapply(iris,levels(iris$Species),mean)
tapply(iris,iris$Species,mean)
tapply(iris$Sepal.Length,iris$Species,mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
colMeans(iris)
library(datasets)
data(mtcars)
?mtcart
?mtcars
mtcars
tapply(mtcars$mpg, mtcars$cyl,mean)
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))[8]-with(mtcars, tapply(hp, cyl, mean))[4]
with(mtcars, tapply(hp, cyl, mean))["8"]-with(mtcars, tapply(hp, cyl, mean))["4"]
with(mtcars, tapply(hp, cyl, average))
with(mtcars, tapply(hp, cyl, mean))["4"]-with(mtcars, tapply(hp, cyl, mean))["8"]
209.21429-26.66364
209.21429-82.63636
debug(ls)
ls()
x
q
x
?
set.seed(1)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
?hist
install.packages(foreach)
install.packages("foreach")
dnorm(-5)
dnorm(5)
dnorm(-1000)
dnorm(-10)
?dt
install.packages("TDist")
vals <- times( k ) %do% mean( rexp(40, 0.2) )
library(foreach)
library(ggplot2)
library(stats)
vals <- times( k ) %do% mean( rexp(40, 0.2) )
k <- 1000
vals <- times( k ) %do% mean( rexp(40, 0.2) )
vals[1:10]
dt(vals[1],39)
dt(vals[1],40-1)
dt(vals[2],40-1)
dt(vals,39)[1:10]
ggplot(aes(x=dt(vals,39))) + geom_density(alpha=.3)
ggplot(x=dt(vals,39)) + geom_density(alpha=.3)
ggplot(dt(vals,39)) + geom_density(alpha=.3)
d <- data.frame(x = dt(vals,39))
ggplot(d, aes(x=x) + geom_density(alpha=.3)
ggplot(d, aes(x=x)) + geom_density(alpha=.3)
d <- data.frame(x = vals)
ggplot(d, aes(x=x)) + geom_density(alpha=.3)
(1/0.2)/sqrt(1000)
?qnorm
set.seed(1414)
k <- 1000
vals <- times( k ) %do% mean( rexp(40, 0.2) )
var_fact <- variance( vals )
var_fact <- var( vals )
var_theo <- (1/0.2)^2/40
df <- data.frame ( vals = vals )
ggplot(df, aes(x=vals)) +
geom_density(alpha=.2, fill="red") +
geom_vline(aes(xintercept=mean(vals, na.rm=T)),
color="red", linetype="dashed", size=1) +
stat_function(fun = dnorm, args=list(mean=5, sd=sqrt(val_theo))
)
library(datasets)
data(ToothGrowth)
head(ToothGrowth)
str(head(ToothGrowth))
ToothGrowth
ToothGrowth[ ToothGrowth[,2] ="VC"]
ToothGrowth[ ToothGrowth[,2] =="VC"]
ToothGrowth[ ToothGrowth[,2] =="VC", ]
ToothGrowth[ ToothGrowth[,2] =="OJ", ]
library(ggplot2)
library(stats)
library(datasets)
data(ToothGrowth)
head(ToothGrowth)
str(head(ToothGrowth))
set.seed(1414)
g1 <- ToothGrowth$dose[1 : 30]
g1
g2 <- sleep$extra[31 : 60]
g2
g2 <- ToothGrowth$dose[31 : 60]
g2
difference <- g2 - g1
mn <- mean(difference)
s <- sd(difference)
n <- 30
mn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n)
mn
difference
g1 <- ToothGrowth$len[1 : 30]
g2 <- ToothGrowth$len[31 : 60]
difference <- g2 - g1
mn <- mean(difference)
mn
s <- sd(difference)
n <- 30
s
mn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n)
t.test(difference)
t.test(g2, g1, paired = TRUE)
t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = ToothGrowth)
t.test(len ~ I(relevel(group, 2)), paired = TRUE, data = ToothGrowth)
t.test(len ~ I(relevel(supp, 2)), paired = TRUE, data = ToothGrowth)
t.test(len ~ I(relevel(dose, 2)), paired = TRUE, data = ToothGrowth)
t.test(I(relevel(supp, 2) ~ len), paired = TRUE, data = ToothGrowth)
t.test(len ~ I(relevel(supp, 2)), paired = TRUE, data = ToothGrowth)
difference
g1
g2
ToothGrowth$supp[1 : 30]
ToothGrowth$supp[31 : 60]
ToothGrowth
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summary(fit)$coefficients
beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)
e<-y-beta0-beta1*x
sigma<-sqrt(sum(e^2)/(n-2))
n<-length(x)
sigma<-sqrt(sum(e^2)/(n-2))
sigma
library(UsingR)
data(mtcars)
str(mtcars)
y<-mtcars$mpg;x<-mtcars$wt;n<-length(y)
fit<-lm(y~x)
summary(fit)$coefficients
mean(x)
sumCoef<-summary(fit)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
fit2<-lm(y~I(x - mean(x))
)
fit2<-lm(y~I(x - mean(x)))
summary(fit2)$coefficients
sumCoef<-summary(fit2)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
?mtcars
fit2<-lm(y~I(x - 3))
sumCoef<-summary(fit2)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
y<-mtcars$mpg;x<-mtcars$wt;n<-length(y)
fit2<-lm(y~I(x - 3))
sumCoef<-summary(fit2)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
fit1<-lm(y~x)
sumCoef<-summary(fit)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
sumCoef[1,1]+sumCoef[2,1]*3
(sumCoef[1,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2])+(sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2])*3
sumCoef[1,1]+sumCoef[2,1]*3+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
fit2<-lm(y~I(x - 3))
sumCoef<-summary(fit2)$coefficients
sumCoef
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
21.251711+2*0.5519713
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]+3*sumCoef[2,1]
fit1<-lm(y~x)
sumCoef<-summary(fit)$coefficients
sumCoef
37.285126+3*(-5.344472)
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
37.285126+3*(-5.344472)+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
fit2<-lm(y~I(x - 3))
sumCoef<-summary(fit2)$coefficients
sumCoef
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
fit2<-lm(y~I(x - 2))
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
y<-mtcars$mpg;x<-mtcars$wt;n<-length(y)
beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)
e1<-y-beta0
e2<-y-beta0-beta1*x
sigma1<-sqrt(sum(e1^2)/(n-2))
sigma2<-sqrt(sum(e2^2)/(n-2))
sigma1/sigma2
sigma2/sigma1
sum(e1^2)/sum(e2^2)
sum(e2^2)/sum(e1^2)
e1
e2
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit1<-lm(y~x)
sumCoef<-summary(fit1)$coefficients
sumCoef
y<-mtcars$mpg;x<-mtcars$wt;n<-length(y)
fit1<-lm(y~x)
sumCoef<-summary(fit1)$coefficients
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit1$df)*sumCoef[1,2]
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit1$df)*sumCoef[2,2]
fit2<-lm(y~I(x - mean(x)))
sumCoef2<-summary(fit2)$coefficients
sumCoef2[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef2[1,2]
sumCoef2[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef2[2,2]
y<-mtcars$mpg;x<-mtcars$wt/2;n<-length(y)
fit1<-lm(y~x)
sumCoef1<-summary(fit1)$coefficients
sumCoef1
sumCoef1[1,1]+c(-1,1)*qt(.975,df=fit1$df)*sumCoef1[1,2]
sumCoef1[2,1]+c(-1,1)*qt(.975,df=fit1$df)*sumCoef1[2,2]
?I
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Case ~ ., method="rpart", data=segmentationOriginal)
library(rattle)
install.packages("rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
str(segmentationOriginal$Case)
modFit$finalModel
str(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Class, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=segmentationOriginal)
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
install.packages("pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
names(olive)
olive = olive[,-1]
names(olive)
inTrain <- createDataPartition(y=olive$Area, p=0.7, list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
modFit <- train(Area ~ ., method="tree", newdata = as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~ ., method="rpart", newdata = as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~ ., method="rpart", data = as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~ ., method="tree", data = as.data.frame(t(colMeans(olive))))
head(as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~ ., method="rpart", data = olive)
?tree
install.package("tree")
install.packages("tree")
install.packages("tree")
library(tree)
?tree
modFit <- tree(Area ~ ., data = olive)
modFit
?predict
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
head(olive)
str(olive$Area)
levels(olive$Area)
tail(olive$Area)
length(olive)
olive$Area
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(SAheart)
modFit <- train(chd ~ I(age+alcohol+obesity+tobacco+typea+ldl), method="glm", family="binomial", data = SAheart)
modFit
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(testing$chd, predict(modFit,testing[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] ))
head(testing[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] )
head(testing[,"age"])
names(testing)
head(testSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] )
head(testSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] )
missClass(testSA$chd, predict(modFit,testSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] ))
missClass(trainSA$chd, predict(modFit,trainSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] ))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit <- train(chd ~ I(age+alcohol+obesity+tobacco+typea+ldl), method="glm", family="binomial", data = SAheart)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(modFit,testSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] ))
missClass(trainSA$chd, predict(modFit,trainSA[,c("age","alcohol","obesity", "tobacco", "typea", "ldl")] ))
names(SAheart)
trainSA <- trainSA[,-c("sbp","adiposity", "famhist", )]
trainSA <- trainSA[,-c("sbp","adiposity", "famhist")]
trainSA <- trainSA[,!c("sbp","adiposity", "famhist")]
trainSA <- trainSA[,-c(1,4,5)]
names(trainSA)
testSA <- testSA[,-c(1,4,5)]
modFit <- train(chd ~ ., method="glm", family="binomial", data = trainSA)
missClass(testSA$chd, predict(modFit,testSA))
missClass(trainSA$chd, predict(modFit,trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.train)
set.seed(33833)
?train
modFit <- train(y ~ . , data=vowel.train, method="rf", importance="varImp", prox=TRUE)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
modFit <- train(y ~ . , data=vowel.train, method="rf", importance="varImp", prox=TRUE)
warnings()[1]
modFit <- train(y ~ . , data=vowel.train, method="rf", importance=TRUE, prox=TRUE)
varImp(modFit$finalModel)
varImp(modFit$finalModel)
order(arImp(modFit$finalModel)[,1])
arImp(modFit$finalModel)[,1]
varImp(modFit$finalModel)[,1]
as.data.frame(varImp(modFit$finalModel))
as.data.frame(varImp(modFit$finalModel)[,1]
as.data.frame(varImp(modFit$finalModel)[,1])
order(as.data.frame(varImp(modFit$finalModel)[,1]))
order(as.data.frame(varImp(modFit$finalModel)[,2]))
order(as.data.frame(varImp(modFit$finalModel)[,3]))
order(as.data.frame(varImp(modFit$finalModel)[,4]))
order(as.data.frame(varImp(modFit$finalModel)[,5]))
order(1,2,3)
order(c(1,2,3)
)
order(as.data.frame(c(1,2,3)))
order(as.data.frame(1,2,3))
order(1,2,3)
mean(varImp(modFit$finalModel)[1,]))
mean(varImp(modFit$finalModel)[1,])
mean(as.data.frame(varImp(modFit$finalModel)[1,]))
varImp(modFit$finalModel)[1,])
varImp(modFit$finalModel)[1,]
mean(varImp(modFit$finalModel)[1,])
modFit$finalModel)
modFit$finalModel
varImp(modFit$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Case ~ ., method="rpart", data=segmentationOriginal)
?rpart
predict(modFit, newdata=c(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2))
modFit
modFit$finalModel
inTrain <- createDataPartition(y=segmentationOriginal$Class, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=segmentationOriginal)
predict(modFit, newdata=c(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2))
modFit$finalModel
?read.csv
getwd()
setwd("/Users/Igor/BigData/Coursera/_PublicFolder/datasciencecoursera/08 Practical Machine Learning")
getwd()
source("PA1 v0.01.Rmd")
trainingDestfilename <- "pml-training.csv"
